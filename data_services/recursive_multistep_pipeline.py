
from sklearn.pipeline import Pipeline
import pandas as pd
import numpy as np
from typing import Callable, Any, Dict


class RecursiveMultiStepPipeline(Pipeline):
    def __init__(
            self,
            prediction_lookahead: int,
            step_size: int,
            pipeline_func: Callable,
            model_params: dict,
            input_params: dict,
            target: str,
    ):
        """
        Wrapper class which runs the pipeline generated by the "pipeline_func" in a multi-step recursive framework, i.e.
        executed multiple times, predicting the target value for the next step (up to the prediction_lookahead), and taking
        the predicted target value from the previous iteration as input ("recursive_feature")
        """

        self.prediction_lookahead = prediction_lookahead  # minutes
        self.step_size = step_size # minutes
        self.pipeline_func = pipeline_func
        self.model_params = model_params
        self.input_params = input_params
        self.target = target


    def single_step_data(
            self,
            data: pd.DataFrame,
            step_lookahead: int,
            features: pd.DataFrame # including "name" and "lat" (lookahead time)
    ) -> pd.DataFrame:

        # Fields of interest for current step_lookahead, and model_lookahead
        features_lookaheads =list(range(step_lookahead + self.step_size,
                                         self.model_params['lookahead'] + step_lookahead + self.step_size,
                                         self.step_size))

        ###
        # Series type features
        ###
        # Obtain feature names for matching feature lookaheads
        df = features[features['lat'].isin(features_lookaheads)]
        data_r = data[df['name']].copy()
        # Rename fields, using step_lookahead as offset
        data_r.columns = [v.rsplit('_', 1)[0] + '_' + str(int(v.rsplit('_', 1)[1]) - step_lookahead)
                          for v in data_r[df['name']].columns]

        # Add step_lookahead
        data_r['step_lookahead'] = step_lookahead

        # Timestamp taking into account step_lookahead
        data_r.insert(0, 'timestamp', data['timestamp'] + pd.Timedelta(minutes=step_lookahead))

        # Original timestamp from source data
        data_r.insert(1, 'timestamp_original', data['timestamp'])

        # Add target if available
        if self.target in data:
            data_r[self.target] = [v['value'][v['lookahead'] == (step_lookahead + self.step_size)][0] for v in
                                   data[self.target]]

        # Add group if available
        if 'group' in data:
            data_r['group'] = data['group']

        return data_r

    def to_multistep_data(
            self,
            data: pd.DataFrame
    ) -> pd.DataFrame:

        features = get_features_df(data.columns, self.input_params)

        data_all = []
        for step_lookahead in range(0, self.prediction_lookahead, self.step_size):
            data_all.append(self.single_step_data(data,
                                                  step_lookahead,
                                                  features),)

        data_multistep = pd.concat(data_all)

        # Add recursive feature, used for training only
        data_multistep = pd.merge(data_multistep,
                                  data[['timestamp', self.model_params['recursive_feature']]],
                                  how='left', on='timestamp')

        return data_multistep

    def fit(
            self,
            X: pd.DataFrame,
            y: pd.Series,
    ) -> object:

        data = X
        data[self.target] = y

        data_multistep = self.to_multistep_data(data)
        self.features_multistep = get_features_df(data_multistep.columns, self.input_params)

        # Even if all core features in data are valid, the multistep process can lead to missing recursive_feature values
        # if recursive_feature values are not available for all steps lookahead. Only affects training, .predict will not
        # have missing values if data does not include missing values
        idx_notnull = data_multistep[
                          list(self.features_multistep['name'][self.features_multistep['is_core']])+[self.target]].isnull().any(
            axis=1) == False

        data_multistep = data_multistep[idx_notnull]

        # Initialize pipeline. Not ideal, but needs to be initialized here to be configured per data_multistep, not data
        self.core_pipeline = self.pipeline_func(data_multistep, self.features_multistep, self.model_params)

        self.core_pipeline.fit(
            data_multistep[list(self.features_multistep['name'])+['step_lookahead']],
            data_multistep[self.target]
        )

        return self

    def predict(
            self,
            X: pd.DataFrame,
    ) -> np.ndarray:

        data_multistep = self.to_multistep_data(X)

        preds = []
        # Loop over steps and use previous prediction to populate recursive_feature
        for step_lookahead in np.sort(data_multistep['step_lookahead'].unique()):

            step_df = data_multistep.loc[data_multistep['step_lookahead'] == step_lookahead].copy()

            if step_lookahead > 0:  # skip first iteration, use actuals
                # Add recursive_feature from previous iteration
                step_df = pd.merge(step_df.drop(columns=self.model_params['recursive_feature']),
                                   step_df_prev, on='timestamp_original').rename(
                    columns={'preds': self.model_params['recursive_feature']})

            # Obtain predictions
            step_df['preds'] = self.core_pipeline.predict(step_df[list(self.features_multistep['name'])+['step_lookahead']])

            step_df_prev = step_df[['timestamp_original', 'preds']]
            preds.append(step_df[['timestamp_original', 'preds', 'step_lookahead']])

        # Format preds
        preds_df = pd.concat(preds)
        preds_df = preds_df.groupby(['timestamp_original']).agg(list)

        preds_col = []
        for idx, row in preds_df.iterrows():
            preds_col.append({'value': np.array(row['preds']), 'lookahead': np.array(row['step_lookahead'])+self.step_size})


        preds_df['preds'] = preds_col
        preds_df = preds_df.reindex(index=X['timestamp'])  # ensure order matches input

        return preds_df['preds'].values


def get_features_df(
        columns: np.array,
        inputs_params: Dict[str, Any]
) -> Dict[str, Any]:
    # Formats features info and identifies all the features for type series (e.g. wind_15, wind_30, wind_45, etc.)
    features = {'name': [],
                'type': [],
                'constraints': [],
                'encoder': [],
                'lat': [],
                'is_core': []}

    for feature in inputs_params:
        if inputs_params[feature]['series'] == False:
            features['name'].append(feature)
            features['type'].append(inputs_params[feature]['type'])
            if 'constraints' in inputs_params[feature]:
                features['constraints'].append(inputs_params[feature]['constraints'])
            else:
                features['constraints'].append({})
            features['encoder'].append(inputs_params[feature]['encoder'])
            features['lat'].append(None)
            if 'core' in inputs_params[feature]:
                features['is_core'].append(inputs_params[feature]['core'])
            else:
                features['is_core'].append(False)
        else:
            for v in [c for c in columns if feature in c]:
                x = v.split(feature + '_')
                if (len(x) == 2) and x[1].isnumeric():
                    features['name'].append(v)
                    features['type'].append(inputs_params[feature]['type'])
                    if 'constraints' in inputs_params[feature]:
                        features['constraints'].append(inputs_params[feature]['constraints'])
                    else:
                        features['constraints'].append({})
                    features['encoder'].append(inputs_params[feature]['encoder'])
                    features['lat'].append(int(x[-1]))
                    if 'core' in inputs_params[feature]:
                        features['is_core'].append(inputs_params[feature]['core'])
                    else:
                        features['is_core'].append(False)

    for v in features:
        features[v] = np.array(features[v])

    return pd.DataFrame(features)

